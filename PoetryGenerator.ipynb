{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP64/vmafICkeDqaystx6EG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahmi54321/nlp_poerty-generator/blob/main/PoetryGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp5UQyhgIp49"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionaries to represent our probabilities\n",
        "\n",
        "initial = {} # start of a phrase\n",
        "first_order = {} # second word only\n",
        "second_order = {}"
      ],
      "metadata": {
        "id": "ylRm9IOQI_m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(s):\n",
        "  return s.translate(str.maketrans('','',string.punctuation))"
      ],
      "metadata": {
        "id": "-xIR8nSeJwTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYoD5s66J_8V",
        "outputId": "90fff7e6-65ca-49e7-cfdd-0f02498df664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-16 03:47:42--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56286 (55K) [text/plain]\n",
            "Saving to: ‘robert_frost.txt’\n",
            "\n",
            "robert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-06-16 03:47:43 (1.27 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function will take in three items a dictionary, a key and a value\n",
        "# the key will represent some starting word or pairs of words in the second order case\n",
        "\n",
        "def add2dict(d, k, v):\n",
        "  if k not in d:\n",
        "    d[k] = []\n",
        "  d[k].append(v)"
      ],
      "metadata": {
        "id": "Npr5eHD8KNE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to traverse our dataset where we make us of the function we just wrote to populate the dictionaries above\n",
        "\n",
        "for line in open('robert_frost.txt'):\n",
        "  tokens = remove_punctuation(line.rstrip().lower()).split()\n",
        "\n",
        "  T = len(tokens)\n",
        "  for i in range(T):\n",
        "    t = tokens[i]\n",
        "    if i == 0:\n",
        "      # measure the distribution of the first word\n",
        "      initial[t] = initial.get(t, 0.) + 1\n",
        "    else:\n",
        "      t_1 = tokens[i-1]\n",
        "      if i == T - 1:\n",
        "        # measure probability of ending the line\n",
        "        add2dict(second_order, (t_1, t), 'END')\n",
        "      if i == 1:\n",
        "        # measure distribution of second word\n",
        "        # given only first word\n",
        "        add2dict(first_order, t_1, t)\n",
        "      else:\n",
        "        t_2 = tokens[i-2]\n",
        "        add2dict(second_order, (t_2, t_1), t)\n"
      ],
      "metadata": {
        "id": "BZ_awZO5LO23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the distributions\n",
        "initial_total = sum(initial.values())\n",
        "for t, c in initial.items():\n",
        "    initial[t] = c / initial_total"
      ],
      "metadata": {
        "id": "AnPAA7adMujz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n",
        "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
        "\n",
        "def list2pdict(ts):\n",
        "  # turn each list of possibilities into a dictionary of probabilities\n",
        "  d = {}\n",
        "  n = len(ts)\n",
        "  for t in ts:\n",
        "    d[t] = d.get(t, 0.) + 1\n",
        "  for t, c in d.items():\n",
        "    d[t] = c / n\n",
        "  return d\n"
      ],
      "metadata": {
        "id": "NQlN8aljNVcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t_1, ts in first_order.items():\n",
        "  # replace list with dictionary of probabilities\n",
        "  first_order[t_1] = list2pdict(ts)\n"
      ],
      "metadata": {
        "id": "cfShx2ewN0Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, ts in second_order.items():\n",
        "  second_order[k] = list2pdict(ts)"
      ],
      "metadata": {
        "id": "pEYgJKbBOAx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function that will sample a word given a dictionary of probabilities\n",
        "\n",
        "def sample_word(d):\n",
        "  # print \"d:\", d\n",
        "  p0 = np.random.random()\n",
        "  # print \"p0:\", p0\n",
        "  cumulative = 0\n",
        "  for t, p in d.items():\n",
        "    cumulative += p\n",
        "    if p0 < cumulative:\n",
        "      return t\n",
        "  assert(False) # should never get here\n"
      ],
      "metadata": {
        "id": "dstCeGBAOND-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate poems\n",
        "\n",
        "def generate():\n",
        "  for i in range(4): # generate 4 lines\n",
        "    sentence = []\n",
        "\n",
        "    # initial word\n",
        "    w0 = sample_word(initial)\n",
        "    sentence.append(w0)\n",
        "\n",
        "    # sample second word\n",
        "    w1 = sample_word(first_order[w0])\n",
        "    sentence.append(w1)\n",
        "\n",
        "    # second-order transitions until END\n",
        "    while True:\n",
        "      w2 = sample_word(second_order[(w0, w1)])\n",
        "      if w2 == 'END':\n",
        "        break\n",
        "      sentence.append(w2)\n",
        "      w0 = w1\n",
        "      w1 = w2\n",
        "    print(' '.join(sentence))\n"
      ],
      "metadata": {
        "id": "XGgF-7q7O99-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MTx3yfkPyii",
        "outputId": "4cc7b79e-f2eb-4bf9-f060-a2deb0a90c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i went to bed alone and left me\n",
            "might just as empty\n",
            "but it isnt as if and thats not all the money goes so fast\n",
            "you couldnt call it living for it aint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise:\n",
        "#\n",
        "# Determine the vocabulary size (V)\n",
        "# We know that pi has shape V, A1 has shape V x V, and A2 has shape V x V x V\n",
        "#\n",
        "# In comparison, how many values are stored in our dictionaries?\n"
      ],
      "metadata": {
        "id": "GUVcJM07QYoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2:\n",
        "# We can skip the step where we accumulate all the possible next words in a list\n",
        "# E.g. [cat, cat, dog, dog, dog, ...]\n",
        "#\n",
        "# Instead, like we do with the initial state distribution, create the dictionary\n",
        "# of counts directly as you loop through the data.\n",
        "#\n",
        "# You'll no longer need list2pdict()\n"
      ],
      "metadata": {
        "id": "PNL1Kn7mQa-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}